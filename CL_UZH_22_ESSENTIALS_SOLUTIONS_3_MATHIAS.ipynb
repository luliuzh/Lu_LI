{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luliuzh/Lu_LI/blob/main/CL_UZH_22_ESSENTIALS_SOLUTIONS_3_MATHIAS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Code I have shown on the slides"
      ],
      "metadata": {
        "id": "McfceaFLiLPU"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQ1E3G2B1XVF"
      },
      "source": [
        "from nltk.util import ngrams\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "def sorted_bigrams(s):\n",
        "  tokens = s.split(\" \")\n",
        "  bigrams = list(ngrams(tokens, 2))\n",
        "  c = Counter(bigrams)\n",
        "\n",
        "  return c.most_common()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wtCAQB8s1kmZ",
        "outputId": "f5f1fc3f-7029-4e53-b4a3-2e670c4f2ada"
      },
      "source": [
        "s = \"T h e m e t h ane l ane i s s ane\"\n",
        "\n",
        "sorted_bigrams(s)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('T', 'h'), 1),\n",
              " (('h', 'e'), 1),\n",
              " (('e', 'm'), 1),\n",
              " (('m', 'e'), 1),\n",
              " (('e', 't'), 1),\n",
              " (('t', 'h'), 1),\n",
              " (('h', 'ane'), 1),\n",
              " (('ane', 'l'), 1),\n",
              " (('l', 'ane'), 1),\n",
              " (('ane', 'i'), 1),\n",
              " (('i', 's'), 1),\n",
              " (('s', 's'), 1),\n",
              " (('s', 'ane'), 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ANzOZizwquw"
      },
      "source": [
        "# Exercise 3.5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mh1mGFSexFu4",
        "outputId": "e90f2ae1-deb8-4e1a-d32d-80421d0f2d2f"
      },
      "source": [
        "! python -m spacy download en"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_sm==2.2.5\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.0 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.6.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
            "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
            "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
            "You can now load the model via spacy.load('en')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM8dffeZ2aJc"
      },
      "source": [
        "import spacy\n",
        "from spacy import displacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-W4uhwhwolT"
      },
      "source": [
        "def print_named_entities(s: str) -> None:\n",
        "\n",
        "  doc = nlp(s)\n",
        "\n",
        "  for ent in doc.ents:\n",
        "      print(ent.text, ent.start_char, ent.end_char, ent.label_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuA8YpqkxSxx",
        "outputId": "61772c74-fe54-4b9a-c505-206419082002"
      },
      "source": [
        "print_named_entities(\"My name is Hulk Hogan and I shot an elephant on the Bahamas and sold it for $30.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hulk Hogan 11 21 PERSON\n",
            "Bahamas 52 59 GPE\n",
            "30 77 79 MONEY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhNIezrswzbP"
      },
      "source": [
        "def display_named_entities(s: str) -> None:\n",
        "  doc = nlp(s)\n",
        "\n",
        "  displacy.render(doc, style=\"ent\", jupyter=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "jBfYXrXTxdYG",
        "outputId": "9d859ed9-200c-4a5b-8a70-5594ee9157eb"
      },
      "source": [
        "display_named_entities(\"My name is Hulk Hogan and I shot an elephant on the Bahamas and sold it for $30.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">My name is \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Hulk Hogan\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " and I shot an elephant on the \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bahamas\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " and sold it for $\n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    30\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
              "</mark>\n",
              ".</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "_9L3spJD_tIf",
        "outputId": "61296968-697c-4c1f-b496-bce9133155aa"
      },
      "source": [
        "display_named_entities(\"This is a sentence.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.7/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">This is a sentence.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDrgT5scxtBb"
      },
      "source": [
        "## Exercise 3.6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRmkPTgaxh2w"
      },
      "source": [
        "def print_pos_tags(s: str) -> None:\n",
        "\n",
        "  doc = nlp(s)\n",
        "\n",
        "  for token in doc:\n",
        "    print(token.text, token.pos_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6TxYkk8yPnC",
        "outputId": "2de83341-4231-40a0-da6f-38a65f2dcb29"
      },
      "source": [
        "print_pos_tags(\"We climbed the north face of Mount Everest.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We PRON\n",
            "climbed VERB\n",
            "the DET\n",
            "north ADJ\n",
            "face NOUN\n",
            "of ADP\n",
            "Mount PROPN\n",
            "Everest PROPN\n",
            ". PUNCT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGOMD5AoyS9Q"
      },
      "source": [
        "def get_pos_of_face(s: str) -> str:\n",
        "\n",
        "  assert \"face\" in s, \"'face' not found in the input string!\"\n",
        "\n",
        "  doc = nlp(s)\n",
        "\n",
        "  for token in doc:\n",
        "    if token.text == \"face\":\n",
        "      return token.pos_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "2w7xg4hPy_Xl",
        "outputId": "d8f3447f-866a-4149-f91b-f5b842221016"
      },
      "source": [
        "get_pos_of_face(\"We climbed the north face of Mount Everest.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'NOUN'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nN1BtU0xzCFy"
      },
      "source": [
        "TEST_CASES = [(\"NOUN\", \"We climbed the north face of Mount Everest.\"),\n",
        "              (\"VERB\", \"You seem to face some real difficulties.\"),\n",
        "              (\"NOUN\", \"My face was glowing red from the heat.\"),\n",
        "              (\"VERB\", \"Let’s face it, How I Met your Mother is dumb.\")]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7DZl4Q2zaPo"
      },
      "source": [
        "def test_face_pos_is_correct() -> bool:\n",
        "\n",
        "  for expected_pos, sentence in TEST_CASES:\n",
        "    actual_pos = get_pos_of_face(sentence)\n",
        "    assert actual_pos == expected_pos\n",
        "\n",
        "  return True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVcwtvWd0C9n"
      },
      "source": [
        "test_face_pos_is_correct()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGOz0U4Rztrt"
      },
      "source": [
        "def test_fails_if_face_not_in_sentence():\n",
        "  # this should return an AssertionError\n",
        "  get_pos_of_face(\"any input without lowercase FACE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "id": "Am7vvr6o0GSn",
        "outputId": "9362fa82-ccff-43ee-e232-20de7d0d9907"
      },
      "source": [
        "test_fails_if_face_not_in_sentence()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-43bb739d25f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_fails_if_face_not_in_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-20-75a9e34233ad>\u001b[0m in \u001b[0;36mtest_fails_if_face_not_in_sentence\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_fails_if_face_not_in_sentence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;31m# this should return an AssertionError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mget_pos_of_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"any input without lowercase FACE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-13-597a8beb2506>\u001b[0m in \u001b[0;36mget_pos_of_face\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_pos_of_face\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32massert\u001b[0m \u001b[0;34m\"face\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"'face' not found in the input string!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAssertionError\u001b[0m: 'face' not found in the input string!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ROKf7oFy0HNX"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGtCdKmSM_f0"
      },
      "source": [
        "## Exercise 3.9"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### First implementation"
      ],
      "metadata": {
        "id": "kpLGDxc1g68L"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JoR_6LB9OCPV"
      },
      "source": [
        "from typing import List, Set, Tuple, Any\n",
        "from nltk.util import ngrams\n",
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13-5anOHQi9s"
      },
      "source": [
        "def find_most_frequent_bigram(symbols: List[str]) -> Tuple:\n",
        "  bigrams = list(ngrams(symbols, 2))\n",
        "  c = Counter(bigrams)\n",
        "\n",
        "  return c.most_common(1)[0][0]\n",
        "\n",
        "def split_string_into_characters(s: str) -> List[str]:\n",
        "  s = s.replace(\" \", \"\")\n",
        "  return list(s)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwVKht_ENBhP"
      },
      "source": [
        "class BPE:\n",
        "\n",
        "  def __init__(self, desired_vocab_size: int) -> None:\n",
        "\n",
        "    self.desired_vocab_size = desired_vocab_size\n",
        "    self.vocabulary = None  # type: Set\n",
        "\n",
        "    self.current_data = None  # type: List[str]\n",
        "\n",
        "    self.merges = []  # type: List[Tuple[str, str]]\n",
        "\n",
        "  def _initialize_vocab(self) -> List[str]:\n",
        "    \"\"\"\n",
        "    Builds an initial vocabulary of characters.\n",
        "\n",
        "    Return: Returns the list of initial characters found in the data.\n",
        "    \"\"\"\n",
        "    self.vocabulary = set(self.current_data)\n",
        "\n",
        "    return self.vocabulary\n",
        "\n",
        "  def train(self, training_data: str) -> None:\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    training_data = split_string_into_characters(training_data)\n",
        "    self.current_data = training_data\n",
        "\n",
        "    self._initialize_vocab()\n",
        "\n",
        "    while len(self.vocabulary) < self.desired_vocab_size:\n",
        "\n",
        "      # find the most frequent bigram of symbols sym1 and sym2\n",
        "      most_frequent_bigram = find_most_frequent_bigram(self.current_data)\n",
        "\n",
        "      # add the concatenation of sym1, sym2 to the vocabulary\n",
        "      new_symbol = \"\".join(list(most_frequent_bigram))\n",
        "      self.vocabulary.add(new_symbol)\n",
        "\n",
        "      # In the data, merge all occurrences of sym1, sym2\n",
        "      current_data_as_string_with_whitespace = \" \".join(self.current_data)\n",
        "      individual_symbols_with_whitespace = \"%s %s\" % most_frequent_bigram\n",
        "\n",
        "      # record merge operations\n",
        "      self.merges.append((individual_symbols_with_whitespace, new_symbol))\n",
        "\n",
        "      new_data = current_data_as_string_with_whitespace.replace(individual_symbols_with_whitespace, new_symbol)\n",
        "\n",
        "      self.current_data = list(new_data)\n",
        "\n",
        "  def apply(self, input_text: str) -> str:\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    # first split into individual characters\n",
        "    input_text = \" \".join(split_string_into_characters(input_text))\n",
        "\n",
        "    # apply all merges recorded during training\n",
        "    for (individual_symbols_with_whitespace, new_symbol) in self.merges:\n",
        "      input_text = input_text.replace(individual_symbols_with_whitespace, new_symbol)\n",
        "\n",
        "    return input_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train:"
      ],
      "metadata": {
        "id": "V48N9N0vBYwf"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yHcyJUppQlr_"
      },
      "source": [
        "data = \"the methane lane is sane\"\n",
        "desired_size = 12\n",
        "\n",
        "b = BPE(desired_vocab_size=desired_size)\n",
        "\n",
        "b.train(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln8_pwcnSdFY",
        "outputId": "13d5bbfd-fe4d-43b9-877f-4a5ac7d966ed"
      },
      "source": [
        "b.vocabulary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'  ', ' e', 'a', 'an', 'e', 'h', 'i', 'l', 'm', 'n', 's', 't'}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "apply a trained model to a new text:"
      ],
      "metadata": {
        "id": "JniPzurmBZu4"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDGBFDh5S-c_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9666fa17-25e1-4d3e-e847-dc89d79d9059"
      },
      "source": [
        "b.apply(\"methane\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'m e t h an e'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Second implementation (hopefully better)"
      ],
      "metadata": {
        "id": "EzGTt01sVEav"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_most_frequent_bigram(symbols: List[str]) -> Tuple:\n",
        "  bigrams = list(ngrams(symbols, 2))\n",
        "  c = Counter(bigrams)\n",
        "\n",
        "  return c.most_common(1)[0][0]"
      ],
      "metadata": {
        "id": "amQCYjLdViRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_sub_list_indexes(sl,l):\n",
        "    \"\"\"\n",
        "    Source: https://stackoverflow.com/a/17870684/1987598\n",
        "    \"\"\"\n",
        "    results=[]\n",
        "    sll=len(sl)\n",
        "    for ind in (i for i,e in enumerate(l) if e==sl[0]):\n",
        "        if l[ind:ind+sll]==sl:\n",
        "            results.append((ind,ind+sll-1))\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "4XYGUOxtVRw0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def concatenate_most_frequent_bigram_in_data(most_frequent_bigram: Tuple[str, str],\n",
        "                                             current_data: List[str]) -> List[str]:\n",
        "    \"\"\"\n",
        "    Adapted from: https://stackoverflow.com/a/1142879/1987598\n",
        "    \"\"\"\n",
        "\n",
        "    sublist_indexes = find_sub_list_indexes(list(most_frequent_bigram), current_data)\n",
        "\n",
        "    for sublist_index in reversed(sublist_indexes):\n",
        "        index_sym_1, index_sym_2 = sublist_index\n",
        "        current_data[index_sym_1:index_sym_2+1] = [''.join(current_data[index_sym_1:index_sym_2+1])]\n",
        "\n",
        "    return current_data"
      ],
      "metadata": {
        "id": "60LIbZh2cxrv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BPEBetter:\n",
        "\n",
        "  def __init__(self, desired_vocab_size: int) -> None:\n",
        "\n",
        "    self.desired_vocab_size = desired_vocab_size\n",
        "    self.vocabulary = None  # type: Set\n",
        "\n",
        "    self.current_data = None  # type: List[str]\n",
        "\n",
        "    self.merges = []  # type: List[Tuple[str, str]]\n",
        "\n",
        "  def _initialize_vocab(self) -> List[str]:\n",
        "    \"\"\"\n",
        "    Builds an initial vocabulary of characters.\n",
        "\n",
        "    Return: Returns the list of initial characters found in the data.\n",
        "    \"\"\"\n",
        "    self.vocabulary = set(self.current_data)\n",
        "\n",
        "    return self.vocabulary\n",
        "\n",
        "\n",
        "  def train(self, training_data: str) -> None:\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "\n",
        "    # split training data into characters\n",
        "    training_data = list(training_data)\n",
        "    self.current_data = training_data\n",
        "\n",
        "    self._initialize_vocab()\n",
        "\n",
        "    expected_number_of_steps = self.desired_vocab_size - len(self.vocabulary)\n",
        "\n",
        "    print(\"Expected number of steps: %d\" % expected_number_of_steps)\n",
        "\n",
        "    num_steps = 0\n",
        "\n",
        "    while len(self.vocabulary) < self.desired_vocab_size:\n",
        "\n",
        "      num_steps += 1\n",
        "\n",
        "      print(\"Step %d of %d ...\" % (num_steps, expected_number_of_steps))\n",
        "\n",
        "      # find the most frequent bigram of symbols sym1 and sym2\n",
        "      most_frequent_bigram = find_most_frequent_bigram(self.current_data)\n",
        "\n",
        "      # add the concatenation of sym1, sym2 to the vocabulary\n",
        "      new_symbol = \"\".join(list(most_frequent_bigram))\n",
        "      self.vocabulary.add(new_symbol)\n",
        "\n",
        "      # In the data, merge all occurrences of sym1, sym2\n",
        "      self.current_data = concatenate_most_frequent_bigram_in_data(most_frequent_bigram, self.current_data)\n",
        "\n",
        "      # record merge operations (for applying the model later)\n",
        "      self.merges.append(most_frequent_bigram)\n",
        "\n",
        "\n",
        "  def apply(self, input_text: str) -> str:\n",
        "    \"\"\"\n",
        "    \"\"\"\n",
        "    # first split into individual characters\n",
        "    input_text = list(input_text)\n",
        "\n",
        "    # apply all merges recorded during training\n",
        "    for most_frequent_bigram in self.merges:\n",
        "        input_text = concatenate_most_frequent_bigram_in_data(most_frequent_bigram, input_text)\n",
        "\n",
        "    return input_text"
      ],
      "metadata": {
        "id": "177cmHRnLyeD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = \"the methane lane is sane\"\n",
        "desired_size = 15\n",
        "\n",
        "b3 = BPEBetter(desired_vocab_size=desired_size)\n",
        "\n",
        "b3.train(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S1olHGfRXSvp",
        "outputId": "2d7de0b2-0b76-44e4-f0c3-2679af1a5854"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected number of steps: 5\n",
            "Step 1 of 5 ...\n",
            "Step 2 of 5 ...\n",
            "Step 3 of 5 ...\n",
            "Step 4 of 5 ...\n",
            "Step 5 of 5 ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b3.vocabulary"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Idy7vsBReaqH",
        "outputId": "59c3bfa7-7f1e-4df3-efa7-37614fef090e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ',\n",
              " 'a',\n",
              " 'an',\n",
              " 'ane ',\n",
              " 'e',\n",
              " 'e ',\n",
              " 'h',\n",
              " 'i',\n",
              " 'l',\n",
              " 'm',\n",
              " 'n',\n",
              " 's',\n",
              " 't',\n",
              " 'th',\n",
              " 'the '}"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b3.apply(\"methane\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_N_LqhjbdQYw",
        "outputId": "e8aff4ef-1bcb-4d70-f937-7884ebc98aac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['m', 'e', 'th', 'an', 'e']"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now try on some larger text:"
      ],
      "metadata": {
        "id": "eYF3B4RwgRt_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://www.gutenberg.org/files/2554/2554-0.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7e0c985-b9cc-47a3-e63a-647fca983894",
        "id": "rKaMexMhgQD5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-13 17:05:47--  https://www.gutenberg.org/files/2554/2554-0.txt\n",
            "Resolving www.gutenberg.org (www.gutenberg.org)... 152.19.134.47, 2610:28:3090:3000:0:bad:cafe:47\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... failed: Connection timed out.\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|2610:28:3090:3000:0:bad:cafe:47|:443... failed: Cannot assign requested address.\n",
            "Retrying.\n",
            "\n",
            "--2023-09-13 17:07:58--  (try: 2)  https://www.gutenberg.org/files/2554/2554-0.txt\n",
            "Connecting to www.gutenberg.org (www.gutenberg.org)|152.19.134.47|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1201520 (1.1M) [text/plain]\n",
            "Saving to: ‘2554-0.txt.1’\n",
            "\n",
            "2554-0.txt.1        100%[===================>]   1.15M  2.80MB/s    in 0.4s    \n",
            "\n",
            "2023-09-13 17:08:06 (2.80 MB/s) - ‘2554-0.txt.1’ saved [1201520/1201520]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "\n",
        "def read_training_data(filepath: str, max_num_lines: Optional[int] = None) -> str:\n",
        "  with open(filepath) as infile:\n",
        "\n",
        "    training_lines = []\n",
        "\n",
        "    lines_seen = 0\n",
        "\n",
        "    for line in infile:\n",
        "      line = line.strip()\n",
        "      training_lines.append(line)\n",
        "\n",
        "      lines_seen += 1\n",
        "\n",
        "      if max_num_lines is not None:\n",
        "        if lines_seen == max_num_lines:\n",
        "          break\n",
        "\n",
        "  return \" \".join(training_lines)"
      ],
      "metadata": {
        "id": "I2AFADOcgQD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_data = read_training_data(\"2554-0.txt\", max_num_lines=10000)"
      ],
      "metadata": {
        "id": "LbagMkDfgQD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "see how many individual characters are in this data:"
      ],
      "metadata": {
        "id": "D5U98gQzgQD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(set(training_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f01c5391-856a-4a7a-abff-212f526e8e7e",
        "id": "7pitB8JDgQD_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "87"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "desired_size = 200\n",
        "\n",
        "b4 = BPEBetter(desired_vocab_size=desired_size)\n",
        "\n",
        "b4.train(training_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a94c9d6-5539-4ecb-ab56-d6a0431f83e4",
        "id": "zWecdy3FgQEA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected number of steps: 113\n",
            "Step 1 of 113 ...\n",
            "Step 2 of 113 ...\n",
            "Step 3 of 113 ...\n",
            "Step 4 of 113 ...\n",
            "Step 5 of 113 ...\n",
            "Step 6 of 113 ...\n",
            "Step 7 of 113 ...\n",
            "Step 8 of 113 ...\n",
            "Step 9 of 113 ...\n",
            "Step 10 of 113 ...\n",
            "Step 11 of 113 ...\n",
            "Step 12 of 113 ...\n",
            "Step 13 of 113 ...\n",
            "Step 14 of 113 ...\n",
            "Step 15 of 113 ...\n",
            "Step 16 of 113 ...\n",
            "Step 17 of 113 ...\n",
            "Step 18 of 113 ...\n",
            "Step 19 of 113 ...\n",
            "Step 20 of 113 ...\n",
            "Step 21 of 113 ...\n",
            "Step 22 of 113 ...\n",
            "Step 23 of 113 ...\n",
            "Step 24 of 113 ...\n",
            "Step 25 of 113 ...\n",
            "Step 26 of 113 ...\n",
            "Step 27 of 113 ...\n",
            "Step 28 of 113 ...\n",
            "Step 29 of 113 ...\n",
            "Step 30 of 113 ...\n",
            "Step 31 of 113 ...\n",
            "Step 32 of 113 ...\n",
            "Step 33 of 113 ...\n",
            "Step 34 of 113 ...\n",
            "Step 35 of 113 ...\n",
            "Step 36 of 113 ...\n",
            "Step 37 of 113 ...\n",
            "Step 38 of 113 ...\n",
            "Step 39 of 113 ...\n",
            "Step 40 of 113 ...\n",
            "Step 41 of 113 ...\n",
            "Step 42 of 113 ...\n",
            "Step 43 of 113 ...\n",
            "Step 44 of 113 ...\n",
            "Step 45 of 113 ...\n",
            "Step 46 of 113 ...\n",
            "Step 47 of 113 ...\n",
            "Step 48 of 113 ...\n",
            "Step 49 of 113 ...\n",
            "Step 50 of 113 ...\n",
            "Step 51 of 113 ...\n",
            "Step 52 of 113 ...\n",
            "Step 53 of 113 ...\n",
            "Step 54 of 113 ...\n",
            "Step 55 of 113 ...\n",
            "Step 56 of 113 ...\n",
            "Step 57 of 113 ...\n",
            "Step 58 of 113 ...\n",
            "Step 59 of 113 ...\n",
            "Step 60 of 113 ...\n",
            "Step 61 of 113 ...\n",
            "Step 62 of 113 ...\n",
            "Step 63 of 113 ...\n",
            "Step 64 of 113 ...\n",
            "Step 65 of 113 ...\n",
            "Step 66 of 113 ...\n",
            "Step 67 of 113 ...\n",
            "Step 68 of 113 ...\n",
            "Step 69 of 113 ...\n",
            "Step 70 of 113 ...\n",
            "Step 71 of 113 ...\n",
            "Step 72 of 113 ...\n",
            "Step 73 of 113 ...\n",
            "Step 74 of 113 ...\n",
            "Step 75 of 113 ...\n",
            "Step 76 of 113 ...\n",
            "Step 77 of 113 ...\n",
            "Step 78 of 113 ...\n",
            "Step 79 of 113 ...\n",
            "Step 80 of 113 ...\n",
            "Step 81 of 113 ...\n",
            "Step 82 of 113 ...\n",
            "Step 83 of 113 ...\n",
            "Step 84 of 113 ...\n",
            "Step 85 of 113 ...\n",
            "Step 86 of 113 ...\n",
            "Step 87 of 113 ...\n",
            "Step 88 of 113 ...\n",
            "Step 89 of 113 ...\n",
            "Step 90 of 113 ...\n",
            "Step 91 of 113 ...\n",
            "Step 92 of 113 ...\n",
            "Step 93 of 113 ...\n",
            "Step 94 of 113 ...\n",
            "Step 95 of 113 ...\n",
            "Step 96 of 113 ...\n",
            "Step 97 of 113 ...\n",
            "Step 98 of 113 ...\n",
            "Step 99 of 113 ...\n",
            "Step 100 of 113 ...\n",
            "Step 101 of 113 ...\n",
            "Step 102 of 113 ...\n",
            "Step 103 of 113 ...\n",
            "Step 104 of 113 ...\n",
            "Step 105 of 113 ...\n",
            "Step 106 of 113 ...\n",
            "Step 107 of 113 ...\n",
            "Step 108 of 113 ...\n",
            "Step 109 of 113 ...\n",
            "Step 110 of 113 ...\n",
            "Step 111 of 113 ...\n",
            "Step 112 of 113 ...\n",
            "Step 113 of 113 ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b4.apply(\"My English text is nice\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BlfozC0BhKIa",
        "outputId": "e8911412-e458-4488-f4ee-b8e4edd59e73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['M',\n",
              " 'y ',\n",
              " 'E',\n",
              " 'n',\n",
              " 'g',\n",
              " 'l',\n",
              " 'is',\n",
              " 'h',\n",
              " ' t',\n",
              " 'e',\n",
              " 'x',\n",
              " 't ',\n",
              " 'is ',\n",
              " 'n',\n",
              " 'ic',\n",
              " 'e']"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5hz9bz0BhUev"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}